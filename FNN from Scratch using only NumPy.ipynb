{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "vA_Nm4gM4oX9"
      },
      "source": [
        "# FNN from Scratch using only NumPy"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "e7vPaIoU4pqD"
      },
      "source": [
        "the neural network algorithm by creating the model from scratch only with NumPy. You will learn how forward/backpropagation and weight normalization/activation of the simple single-layer neural network work. At the same time, we will continue to practice NumPy. This time we will use the famous MNIST dataset, and you will need to compare the result under different normalization/activation settings of the same architecture."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtWBHOcoqnKH"
      },
      "source": [
        "## 1. Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VA351vjdly0R"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.pipeline import Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCm_Zo2W8Q22"
      },
      "source": [
        "The MNIST dataset was constructed from two datasets of the US National Institute\n",
        "of Standards and Technology (NIST). The training dataset consists of handwritten\n",
        "digits from 250 different people, 50 percent high school students and 50 percent\n",
        "employees from the Census Bureau. Note that the test dataset contains handwritten digits from different people following the same split."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPqJ7jTk7aaG"
      },
      "source": [
        "![alt text](https://dezyre.gumlet.net/images/Exploring+MNIST+Dataset+using+PyTorch+to+Train+an+MLP/MNIST+Dataset.png?w=900&dpr=1.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V29SZpPn8S69"
      },
      "source": [
        "This MNIST dataset can be directly downloaded using scikit-learn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "CmAMpQXwdq4t"
      },
      "outputs": [],
      "source": [
        "X, y = fetch_openml(\"mnist_784\", version=1, return_X_y=True, as_frame=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGUngFc88XsU"
      },
      "source": [
        "It has 70,000 different handwriting instances. It usually has 60,000 instances as a training set and the remaining ones as a test set, but scikit-learn loads it as a whole. So we may need to divide it into two sets ourselves."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(70000, 784)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVuTqRrtlb44",
        "outputId": "16ab1435-eaf3-4267-bff3-0293cd49443a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((70000, 784), (70000,))"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.shape, y.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kILkvez98bVl"
      },
      "source": [
        "We can also check the class distribution - Last time, we dealt with imbalanced data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "YNAjbM-Z8ixF",
        "outputId": "9adb6cf3-0351-436d-99c5-bed9f75d4cbe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<BarContainer object of 10 artists>"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.bar(np.unique(y, return_counts = True)[0], np.unique(y, return_counts = True)[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEc2na5f9tRg"
      },
      "source": [
        "You may also need to apply normalization for better performance. Since it is clear that its maximum value is 255, we can simply normalize it by dividing the whole value by 255. You can use NumPy's broadcasting to divide the matrix by one scalar value. It is also possible to further standardize it to have a centeralized mean, but it's optional. \n",
        "- Apply normalization to X to have the range [0, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "GzXvdYtlmNqi"
      },
      "outputs": [],
      "source": [
        "X_normalized = X / 255.0   # CHANGE IT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmmuNtw2d8dX"
      },
      "source": [
        "If you take a look at `y`, it has string labels! It might be disturbing when we need to handle them later, so let's also convert them to an integer form."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "vfx0EL0wmoyU"
      },
      "outputs": [],
      "source": [
        "y_integer = y.astype(int) # CHANGE IT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqeW4C00l5se"
      },
      "source": [
        "Those will be our simple preprocessing modules! Next we will split the dataset into two parts using scikit-learn's `train_test_split` method.\n",
        "- Use scikit-learn's `train_test_split` to create training and test sets.\n",
        "- Set **train_size** = 60,000 **test_size** = 10,000.\n",
        "- Enable stratification.\n",
        "- use `X_normalized` and `y_integer`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "SiERfT0gddu1"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y_integer, test_size=0.142857,stratify=y)    # CHANGE IT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMldZza-faxL"
      },
      "source": [
        "Here you can check some of the instances that we have."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "TzRs98dodeAF",
        "outputId": "44fd41d2-20e1-43b1-ad0f-e4474dfc5d12"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 10 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, ax = plt.subplots(nrows=2, ncols=5, sharex=True, sharey=True)\n",
        "ax = ax.flatten()\n",
        "for i in range(10):\n",
        "  img = X_train[y_train == i][0].reshape(28, 28)\n",
        "  ax[i].imshow(img, cmap='Greys')\n",
        "ax[0].set_xticks([])\n",
        "ax[0].set_yticks([])\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baT1IBRFqrBJ"
      },
      "source": [
        "## 2. Helper functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NH85Qfu6nbIK"
      },
      "source": [
        "We will develop it with a class representation to use scikit-learn's pipeline. This means we might need to develop `fit` and `transform` methods inside the class. Before creating the class structure, let's create some helper functions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVROBu9_py1h"
      },
      "source": [
        "First, we need to fix the labels, which are now in a sparse form, to have a one-hot encoded form for better computation using NumPy's vectorization. Let's create a function that receives a label vector and transform it into a one-hot encoded label matrix.\n",
        "\n",
        "- Complete the `one_hot` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "msvnKGsR0yUS"
      },
      "outputs": [],
      "source": [
        "def one_hot(y):\n",
        "  \"\"\"\n",
        "  Input:\n",
        "    - y : set of labels\n",
        "\n",
        "  Output:\n",
        "    - onehot: a one-hot-encoded array\n",
        "\n",
        "  This function creates an one-hot encoded representation of the labels.\n",
        "  This means that you will have a set of binary columns indicading each possible class.\n",
        "\n",
        "  You have to develop this one hot encoding strategy without using Python for loop \n",
        "  \"\"\"\n",
        "  m = y.shape[0]\n",
        "  n = np.unique(y).shape[0] \n",
        "  out = np.zeros((m, n))\n",
        "  out[np.arange(m), y] = 1\n",
        "\n",
        "  return out      # CHANGE IT\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dAPaf1708Bs"
      },
      "source": [
        "The expected outcome of the one-hot encoding is as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGFbZ_tN00WK",
        "outputId": "5f95af4b-c0f8-4ca3-9096-5c38bc48f4df"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0., 1., 0., 0.],\n",
              "       [1., 0., 0., 0.],\n",
              "       [0., 0., 1., 0.],\n",
              "       [0., 0., 0., 1.]])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "one_hot(np.array([1,0,2,3]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7niKihIdpYa5"
      },
      "source": [
        "Next we may also need a sigmoid function for the output values as we are dealing with a classification problem. Sigmoid can be represented as follows:\n",
        "\n",
        "$$ h_ \\theta (x) =  \\frac{\\mathrm{1} }{\\mathrm{1} + e^{-x} }  $$ \n",
        "\n",
        "\n",
        "- Complete the sigmoid function below that supports both vectors and scalars."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "hFSCiidT1Drz"
      },
      "outputs": [],
      "source": [
        "def sigmoid(x):\n",
        "  \"\"\"\n",
        "  Input:\n",
        "    - z: input vector or scalar value\n",
        "\n",
        "  Output:\n",
        "    - sigmoid: output sigmoid-transformed vector or scalar value\n",
        "\n",
        "  Calculate the sigmoid value of the input.\n",
        "  \"\"\"\n",
        "  # x = np.clip(x, -250, 250)\n",
        "  np.seterr( over='ignore' )    #added to ignore the overflow error due to the value of x\n",
        "  out = 1 / (1 + np.exp(-x))\n",
        "\n",
        "  return  out    # CHANGE IT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xlugwi8r0O-H"
      },
      "source": [
        "The expected result of the sigmoid function is as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fJNnW22qMQ0",
        "outputId": "415e63df-bb52-4e9c-9d44-09c14a5fe412"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1. , 0. , 0.5])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sigmoid(np.array([np.inf, -np.inf, 0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnfdCK6Fqtls"
      },
      "source": [
        "## 3. Our FCN classifier with the class structure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sn2YtPQk0pXK"
      },
      "source": [
        "Now it's time to create our neural network model from scratch! We will eventually integrate everything into scikit-learn's pipeline, so it's important to have an appropriate class structure. To do this, you may need to extend `BaseEstimator` and `TransformerMixin` to make scikit-learn recognize that our class is a valid classifier.\n",
        "\n",
        "We are going to develop a neural network with one layer for simplicity. That means we will have two different sets of weights.\n",
        "\n",
        "- First layer: [input size (number of features), hidden layer size]\n",
        "- Second layer: [hidden layer size, output size (number of classes)]\n",
        "\n",
        "In our class structure `FullyConnectedNetwork`, we will develop five different methods as follows:\n",
        " - `compile`: Given parameters, we will initialize weight and bias values needed for our neural network model.\n",
        "   - Here, you will initialize bias and weights based on chosen initialization technique.\n",
        "        - We will have three different options: normal, Xavier, and he\n",
        "        - Each technique initializes the weight using the normal distribution but different standard deviation.\n",
        "          - Normal: \n",
        "$ \\mu = 0, \\sigma = 0.1 $\n",
        "          - Xavier: \n",
        "$ \\mu = 0, \\sigma = \\sqrt{\\frac{2}{n_{in} + n_{out}}}$\n",
        "          - He:\n",
        "$ \\mu = 0, \\sigma = \\sqrt{\\frac{2}{n_{in}}}$\n",
        " - `forward`: Perform a forward propagation\n",
        " - `back_propagation`: Perform a back propagation\n",
        "    - You will only need to finish some part of it.\n",
        "      - Weight and bias update\n",
        "      - Derivative of the sigmoid function\n",
        "        - $σ(x)=σ(x)(1−σ(x))$.\n",
        "\n",
        " - `fit`: Run the whole fitting process (forward and backpropagation for each batch)\n",
        " - `cost`: Calculate the cost (cross-entropy) together with the elastic net (l1/l2)\n",
        "   - cross-entropy loss can be calculated as follows:\n",
        " - `predict`: With a trained model, perform a prediction of unseen data by running the forward propagation with the trained weight and bias.\n",
        " - `evaluate`: With trained weight and bias, perform a prediction of test data and calculate the performance metric (in our case, those are training and validation accuracy scores).\n",
        "\n",
        "**This exercise is based on Chapter 12 of the coursebook Python Machine Learning with some modification and additional tasks - so please note that the structure and requirements are not the same.**\n",
        "\n",
        "**You are free to check out the coursebook for reference. However, to solve the tasks, you should understand the logic clearly.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "UxEdUv9hmiTd"
      },
      "outputs": [],
      "source": [
        "class FullyConnectedNetwork(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, n_hidden=30, l2=0., l1=0., epochs=100, eta=0.001, validation_rate = 0.3,\n",
        "                 shuffle=True, batch_size=1, init_technique = \"normal\", seed=None, debug=True):\n",
        "\n",
        "        \"\"\"\n",
        "        We receive the following parameters to construct and test the model:\n",
        "\n",
        "        Input:\n",
        "          - n_hidden: Number of hidden nodes.\n",
        "          - l2: Lambda value for L2-regularization.\n",
        "          - epochs: Number of passes over the training set.\n",
        "          - eta: Learning rate.\n",
        "          - shuffle: Enabling shuffling option of the dataset every epoch.\n",
        "          - batch_size: Number of training examples per batch.\n",
        "          - seed: Random seed for initializing weights and shuffling.\n",
        "        \"\"\"\n",
        "        self.seed = seed\n",
        "        self.random = np.random.RandomState(self.seed)\n",
        "        self.n_hidden = n_hidden\n",
        "        self.l2 = l2\n",
        "        self.l1 = l1\n",
        "        self.epochs = epochs\n",
        "        self.eta = eta\n",
        "        self.validation_rate = validation_rate\n",
        "        self.shuffle = shuffle\n",
        "        self.batch_size = batch_size\n",
        "        self.debug = debug\n",
        "        self.init_technique = init_technique\n",
        "\n",
        "    def compile(self, n_features, n_outputs):\n",
        "        \"\"\"\n",
        "        Initializing the weights of the model\n",
        "\n",
        "        - Here you will initialize bias and weights based on chosen initialization technique.\n",
        "        - We will have three different options: normal, xavier, and he\n",
        "        - Each technique initializes the weight using the normal distribution but different standard deviation.\n",
        "        - Use self.init_technique to check the chosen technique and use self.random to perform the sampling.\n",
        "\n",
        "        Input:\n",
        "          - n_features: input size of the network\n",
        "          - n_outputs: output size of the network\n",
        "          - Unit size of the layer is given as self.n_hidden\n",
        "\n",
        "        Steps:\n",
        "          1. Create lists self.W and self.B.\n",
        "          2. Set mean and standard deviation for different initialization technique.\n",
        "          3. Create weights and bias for the linkage between inputs and the a layer.\n",
        "            - Weight should have the size [n_features, self.n_hidden].\n",
        "            - Bias should have the size [self.n_hidden].\n",
        "            - Weight initialization should be applied to the weights only.\n",
        "            - Bias should be initizalied by zeros.\n",
        "          4. Create weights and bias for the linkage between layer and outputs.\n",
        "            - Weight should have the size [self.n_hidden, n_outputs].\n",
        "            - Bias should have the size [n_outputs].\n",
        "            - Weight initialization should be applied to the weights only.\n",
        "            - Bias should be initizalied by zeros.\n",
        "          5. Save the weights to self.W and biases to self.B.\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        self.B = []\n",
        "        self.W = []\n",
        "\n",
        "        if (self.init_technique == 'normal'):\n",
        "          mean = 0.0\n",
        "          std = 0.1\n",
        "        elif(self.init_technique == 'xavier'):\n",
        "          mean = 0.0\n",
        "          std = np.sqrt(2 / (n_features + n_outputs))\n",
        "        elif(self.init_technique == 'he'):\n",
        "          mean = 0.0\n",
        "          std = np.sqrt(2 / n_features)\n",
        "        \n",
        "\n",
        "        # 1. Creating weights and bias for input -> hidden\n",
        "        # Use specific initialization techniques for weights\n",
        "        # Weights should have the size (n_features, self.n_hidden)\n",
        "        # Use np.zeros for bias with the size 'self.n_hidden'\n",
        "\n",
        "        b_h = np.zeros(self.n_hidden)       # CHANGE IT\n",
        "        w_h = np.random.normal(loc=mean, scale=std, size=(n_features, self.n_hidden))      # CHANGE IT\n",
        "\n",
        "        # 2. Append bias to self.B and weights to self.W\n",
        "        self.B.append(b_h)\n",
        "        self.W.append(w_h)\n",
        "\n",
        "        # 3. Creating weights and bias for hidden -> output\n",
        "        # Use specific initialization techniques for weights\n",
        "        # Weights should have the size (self.n_hidden, n_outputs)\n",
        "        # Use np.zeros for bias with the size 'n_outputs'\n",
        "\n",
        "        b_out = np.zeros(n_outputs)                                             # CHANGE IT\n",
        "        w_out = np.random.normal(loc=mean, scale=std, size=(self.n_hidden, n_outputs))      # CHANGE IT\n",
        "\n",
        "        # 4. Append bias to self.B and weights to self.W\n",
        "        self.B.append(b_out)\n",
        "        self.W.append(w_out)\n",
        "\n",
        "\n",
        "    def forward(self, X):\n",
        "        \"\"\"\n",
        "        Given the dataset X, compute forward propagation step with the weights and bias saved in the list.\n",
        "        This process eventually outputs ten numbers in our case as we have ten outputs.\n",
        "        Forward propagation is performed by multiple chained dot products of inputs and weights.\n",
        "        \n",
        "        Input:\n",
        "          - X: features\n",
        "        \n",
        "        Output:\n",
        "          - Z: Result of dot product of the weights and the previous output for each phase\n",
        "          - A: A list that contains sigmoided values of A\n",
        "        Steps:\n",
        "          1. Create two lists Z and A.\n",
        "          2. Take a dot product of X and the first weight self.W[0] - save the result into Z\n",
        "          3. Apply sigmoid function to the first Z - save the result into A\n",
        "          4. Take a dot product of A and the second weight self.W[1] - save the result into Z\n",
        "          5. Return Z and A\n",
        "        \"\"\"\n",
        "\n",
        "        Z = []\n",
        "        A = []\n",
        "\n",
        "        # Step 1: net input of hidden layer\n",
        "        # - take a dot product of the input features and the initial weights\n",
        "        # - add the outcome to list Z\n",
        "        s_h = np.dot(X,self.W[0]) + self.B[0]\n",
        "        Z.append(s_h)       # CHANGE IT\n",
        "\n",
        "        # Step 2: activation of hidden layer\n",
        "        # - apply the sigmoid function to the dot producted outcome\n",
        "        # - add the outcome to list A\n",
        "        sig_h = sigmoid(Z[0])\n",
        "        A.append(sig_h)       # CHANGE IT\n",
        "\n",
        "        # Step 3: net input of output layer\n",
        "        # - take a dot product of the intermediate features and the weights of the output layer\n",
        "        # - add the outcome to list Z\n",
        "        s_o = np.dot(A[0],self.W[1]) + self.B[1]\n",
        "        Z.append(s_o)         # CHANGE IT\n",
        "\n",
        "        # Step 4: activation output layer\n",
        "        # - apply the sigmoid function to the dot producted outcome\n",
        "        # - add the outcome to list A\n",
        "        sig_o = sigmoid(Z[1])\n",
        "        A.append(sig_o)       # CHANGE IT\n",
        "\n",
        "        return Z, A\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        \n",
        "        Predict class labels by performing forward propagation.\n",
        "\n",
        "        Input: \n",
        "          - X: feature matrix\n",
        "        Output:\n",
        "          - y_pred: Predicted class labels for all data instances.\n",
        "\n",
        "        Steps:\n",
        "          1. Run forward proparation on X and get Z, a.\n",
        "          2. Calculate y_pred by using the output (A[-1]) and with np.argmax\n",
        "            - You have to choose the index of the one with the highest value\n",
        "          3. Return the prediction. You can perform the operation once if you use NumPy's vectorization feature.\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        Z, A = self.forward(X)\n",
        "        y_pred = np.argmax(A[-1],axis=1)\n",
        "\n",
        "        return y_pred    # CHANGE IT\n",
        "\n",
        "    def cost(self, y_truth, y_pred):\n",
        "        \"\"\"\n",
        "        \n",
        "        This function computes the cost for the classification task.\n",
        "        We will also apply Elastic net (combination of l1 and l2)\n",
        "\n",
        "        Input:\n",
        "          - y_truth: \"one-hot encoded\" class labels.\n",
        "          - y_pred: Activation of the output layer (= output of the forward propagation function)\n",
        "          - the weights for l1 and l2 are saved into self.l1 and self.l2\n",
        "        \n",
        "        Output:\n",
        "          - cost: Regularized cost\n",
        "\n",
        "        Steps:\n",
        "          1. Calculate the cross entropy between the truth and predicted values.\n",
        "          2. Add l1 and l2 terms to the cost.\n",
        "            - L1 term is the sum of absolute weight values\n",
        "            - L2 term is the sum of squared weight values\n",
        "            - You should multiply l1 and l2 ratio saved in self.l1 and self.l2\n",
        "            - You should NOT include weights that belong to the bias values.\n",
        "          3. Return the total cost (cross entropy + L1 term + L2 term).\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        # y_truth = np.array(y_truth)\n",
        "        # y_pred = np.array(y_pred)\n",
        "        y_truth_enc = one_hot(y_truth)\n",
        "        y_pred_enc = one_hot(y_pred)\n",
        "\n",
        "        w_h = self.W[0][1:]\n",
        "        w_out = self.W[1][1:]\n",
        "        \n",
        "        # term1 = -y_truth * (np.log(y_pred + 1e-5))\n",
        "        # term2 = (1 - y_truth) * np.log(1 - y_pred + 1e-5)\n",
        "        # cross_entropy = np.sum(term1 - term2)\n",
        "        cross_entropy = -np.sum(y_truth_enc * np.log(y_pred_enc + 1e-5))\n",
        "        l1_term = (self.l1 * (np.sum(np.abs(w_h)) + np.sum(np.abs(w_out))))\n",
        "        l2_term = (self.l2 * (np.sum(np.square(w_h)) + np.sum(np.square(w_out))))\n",
        "\n",
        "        cost = cross_entropy + l1_term + l2_term      # CHANGE IT\n",
        "        \n",
        "        return cost\n",
        "\n",
        "    \n",
        "\n",
        "    def back_propagation(self, X_train, batch_idx, A, y_truth):\n",
        "      \"\"\"\n",
        "      Perform back propagation based on the result of forward propagation and true labels (for each batch).\n",
        "\n",
        "      Input:\n",
        "        X_train: training features\n",
        "        batch_idx: the current batch indices from the fit function\n",
        "        A: Sigmoided output values - the result of forward propagation\n",
        "        y_truth: One-hot encoded true labels\n",
        "\n",
        "      Output:\n",
        "        None\n",
        "        You should update the weights and biases in self.W/self.B\n",
        "\n",
        "      **** You only need to fill in some required parts marked as \"CHANGE THIS PART\" ****\n",
        "      **** To get more information about the backpropagation process: \n",
        "           https://towardsdatascience.com/deriving-backpropagation-with-cross-entropy-loss-d24811edeaf9 ****\n",
        "      \"\"\"\n",
        "\n",
        "      # OUTPUT WEIGHTS (LAYER-OUTPUT)\n",
        "\n",
        "      # δC/δA * δA/δZ\n",
        "      delta_out = A[-1] - y_truth[batch_idx]   \n",
        "      # δC/δA * δA/δZ * δZ/δW\n",
        "      grad_w_out = np.dot(A[0].T, delta_out)\n",
        "      # δC/δA * δA/δZ * δZ/δB\n",
        "      grad_b_out = np.sum(delta_out, axis=0)\n",
        "\n",
        "      #############################################\n",
        "      # CHANGE THIS PART\n",
        "    \n",
        "      # Using the final gradients of the weight and bias (grad_w_out, grad_b_out), we need to update\n",
        "      # Change the values of self.W[1], self.B[1] (output weight and bias).\n",
        "      # - You should also apply l1 and l2 normalization to the weight (not to the bias)\n",
        "      # - You should use the learning rate (self.eta) when changing the value.\n",
        "\n",
        "      l1_w = self.l1 * self.W[1]\n",
        "      l2_w = self.l2 * self.W[1]\n",
        "    \n",
        "      delta_w_out = (grad_w_out + (l1_w + l2_w))                          # CHANGE IT\n",
        "      delta_b_out = grad_b_out                                            # CHANGE IT\n",
        "      self.W[1] -= self.eta * delta_w_out                                 # CHANGE IT\n",
        "      self.B[1] -= self.eta * delta_b_out                                 # CHANGE IT\n",
        "\n",
        "      # END OF CHANGE\n",
        "      #############################################\n",
        "      \n",
        "      # HIDDEN WEIGHTS (INPUT-LAYER)\n",
        "\n",
        "      #############################################\n",
        "      # CHANGE THIS PART\n",
        "\n",
        "      # To continue to take derivatives backwards, we need to be able to take a derivative of the sigmoid function.\n",
        "      # Here we are trying to take derivative of a sigmoided output A[0].\n",
        "      # Derivative of sigmoid σ(x) can be represented as σ(x)(1−σ(x)).\n",
        "      \n",
        "      sigmoid_derivative_h = (A[0]) * (1 - A[0])                # CHANGE IT\n",
        "\n",
        "      # END OF CHANGE\n",
        "      #############################################\n",
        "\n",
        "      delta_h = (np.dot(delta_out, self.W[1].T) * sigmoid_derivative_h)\n",
        "      grad_w_h = np.dot(X_train[batch_idx].T, delta_h)\n",
        "      grad_b_h = np.sum(delta_h, axis=0)\n",
        "\n",
        "      #############################################\n",
        "      # CHANGE THIS PART\n",
        "\n",
        "      # Using the final gradients of the weight and bias (grad_w_h, grad_b_h), we need to update\n",
        "      # Change the values of self.W[0], self.B[0] (output weight and bias).\n",
        "      # - You should also apply l1 and l2 normalization to the weight (not to the bias)\n",
        "      # - You should use the learning rate (self.eta) when changing the value.\n",
        "\n",
        "      # delta_w_h = self.eta * (grad_w_h + (l1_l2 * self.W[0,1:]))       # CHANGE IT\n",
        "      l1_w0 = self.l1 * self.W[0]\n",
        "      l2_w0 = self.l2 * self.W[0]\n",
        "\n",
        "      delta_w_h = (grad_w_h + (l1_w0 + l2_w0))                           # CHANGE IT\n",
        "      delta_b_h = grad_b_h                                               # CHANGE IT\n",
        "      \n",
        "      self.W[0] -= self.eta * delta_w_h                                  # CHANGE IT\n",
        "      self.B[0] -= self.eta * delta_b_h                                  # CHANGE IT\n",
        "\n",
        "      # END OF CHANGE\n",
        "      #############################################\n",
        "\n",
        "    \n",
        "    def evaluate(self, epoch, X_train, X_valid, y_train, y_valid):\n",
        "      \"\"\"\n",
        "      Evaluate performances on the training and validation sets per epoch\n",
        "      \n",
        "      Input:\n",
        "        - epoch: current epoch number\n",
        "        - X_train: training features\n",
        "        - X_valid: validation features\n",
        "        - y_train: training labels\n",
        "        - y_valid: validation labels\n",
        "\n",
        "      Output:\n",
        "        - None\n",
        "        Append the cost and performance metrics of current epoch to self.history\n",
        "      \"\"\"\n",
        "\n",
        "      # Step 1. Call self.forward on X_train to calculate the output with current weights and bias of the model\n",
        "      Z, A = self.forward(X_train)      # CHANGE IT\n",
        "\n",
        "      # Step 2. call predict functions with both X_train and X_valid and save the predicted values accordingly\n",
        "      y_train_pred = self.predict(X_train)      # CHANGE IT\n",
        "      y_valid_pred = self.predict(X_valid)      # CHANGE IT\n",
        "      \n",
        "\n",
        "      # Step 2. Call self.cost with y_train and y_train_pred\n",
        "      # save it into the variable 'cost'\n",
        "      cost = self.cost(y_train,y_train_pred)      # CHANGE IT\n",
        "\n",
        "      # Step 4. Calculate accuracy scores \n",
        "      # - between y_train_pred and y_train\n",
        "      # - between y_valid_pred and y_valid\n",
        "\n",
        "      train_acc = ((np.sum(y_train == y_train_pred)).astype(np.float) / X_train.shape[0])       # CHANGE IT\n",
        "      valid_acc = ((np.sum(y_valid == y_valid_pred)).astype(np.float) / X_valid.shape[0])       # CHANGE IT\n",
        "\n",
        "      # Step 5. Save the results into the dictionary\n",
        "      # This part is already complete\n",
        "      if self.debug == True:\n",
        "        print('%d/%d | Cost: %.2f '\n",
        "                        '| Train/Valid Acc.: %.2f%%/%.2f%% ' %\n",
        "                        (epoch+1, self.epochs, cost,\n",
        "                          train_acc*100, valid_acc*100))\n",
        "\n",
        "      self.history['cost'].append(cost)\n",
        "      self.history['train_acc'].append(train_acc)\n",
        "      self.history['valid_acc'].append(valid_acc)\n",
        "\n",
        "    \n",
        "    def fit(self, X, y):\n",
        "        \"\"\" \n",
        "        \n",
        "        Learn weights from training data.\n",
        "\n",
        "        Input\n",
        "          - X: features (training+validation)\n",
        "          - y: labels\n",
        "\n",
        "        Output\n",
        "          - self.history: information about cost and accuracy scores\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        self.history = {'cost': [], 'train_acc': [], 'valid_acc': []}\n",
        "\n",
        "        # Step 1: Select different training and test sets. Use scikit-learn's train_test_split.\n",
        "        # Turn on the stratification option and use self.validation_rate\n",
        "        X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=self.validation_rate, random_state=self.random, stratify=y)  # CHANGE IT\n",
        "\n",
        "        # Step 2: Compile (initialize) the parameters by running self.compile with correct number of features and outputs\n",
        "        # WRITE YOUR CODE HERE\n",
        "\n",
        "        n_output = np.unique(y_train).shape[0]\n",
        "        n_feature = X_train.shape[1]\n",
        "        self.compile(n_features=n_feature, n_outputs=n_output)   \n",
        "        \n",
        "        #\n",
        "\n",
        "        # Step 3: Prepare one-hot encoded training labels by using one_hot function on y_train\n",
        "        y_train_enc = one_hot(y_train)        # CHANGE IT\n",
        "        \n",
        "\n",
        "        # Step 4: iterate over training epochs\n",
        "        for i in range(self.epochs):\n",
        "\n",
        "            # Step 5: set the indices\n",
        "            # - if self.shuffle is True, shuffle the indices using self.random.shuffle or permutation\n",
        "            indices = np.arange(X_train.shape[0])      # CHANGE IT\n",
        "            if(self.shuffle == True):\n",
        "              self.random.shuffle(indices)\n",
        "\n",
        "            # Step 6: iterate over the data\n",
        "            # - For each iteration, you need to choose the data \n",
        "            for start_idx in range(0, indices.shape[0] - self.batch_size +\n",
        "                                   1, self.batch_size):\n",
        "                batch_idx = indices[start_idx:start_idx + self.batch_size]       # CHANGE IT\n",
        "\n",
        "                # Step 7: Run a forward propagation\n",
        "                Z, A = self.forward(X_train[batch_idx])       # CHANGE IT\n",
        "\n",
        "                # Step 8: Run back propagation \n",
        "                # - Use X_train, batch_idx, A, and y_train_enc\n",
        "                # WRITE YOUR CODE HERE\n",
        "                self.back_propagation(X_train, batch_idx, A, y_train_enc)\n",
        "                #\n",
        "\n",
        "\n",
        "            # call evaluate function after inner loop (whole batch cycles) is complete\n",
        "            # WRITE YOUR CODE HERE\n",
        "            \n",
        "            self.evaluate(i, X_train, X_valid, y_train, y_valid)\n",
        "\n",
        "            #\n",
        "\n",
        "        # Step 9: After all loops are complete, return self.history\n",
        "        return self.history\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "      \"\"\"\n",
        "      We do not need to complete this function.\n",
        "      Leave as it is!\n",
        "      \"\"\"\n",
        "      return self.history\n",
        "    \n",
        "    def score(self, X, y=None):\n",
        "      \"\"\"\n",
        "      Score function for pipeline\n",
        "      Leave as it is!\n",
        "      \"\"\"\n",
        "      y_pred = self.predict(X)\n",
        "      acc = np.sum(y == y_pred) / X.shape[0]\n",
        "      return acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QAzKAjhhwHu"
      },
      "source": [
        "After you finish developing the methods in the class structure, you can create a new instance as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "pEkq3fydrmVw"
      },
      "outputs": [],
      "source": [
        "nn = FullyConnectedNetwork(n_hidden=100, l2=0.01, epochs=100, eta=0.0005, batch_size=100, shuffle=True, seed=12345)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXBBoj_oh5Vt"
      },
      "source": [
        "We will try to run 100 epochs, and depending on your computing power, it might take a few minutes to an hour.\n",
        " - Train your network on `X_train` and `y_train` and save the output to `history`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "uSKfzn3czNrU"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\deept\\AppData\\Local\\Temp/ipykernel_8476/973144741.py:337: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  train_acc = ((np.sum(y_train == y_train_pred)).astype(np.float) / X_train.shape[0])       # CHANGE IT\n",
            "C:\\Users\\deept\\AppData\\Local\\Temp/ipykernel_8476/973144741.py:338: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  valid_acc = ((np.sum(y_valid == y_valid_pred)).astype(np.float) / X_valid.shape[0])       # CHANGE IT\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/100 | Cost: 99306.94 | Train/Valid Acc.: 79.46%/79.22% \n",
            "2/100 | Cost: 73622.05 | Train/Valid Acc.: 84.78%/84.75% \n",
            "3/100 | Cost: 64204.83 | Train/Valid Acc.: 86.72%/86.69% \n",
            "4/100 | Cost: 57124.67 | Train/Valid Acc.: 88.19%/88.08% \n",
            "5/100 | Cost: 53590.45 | Train/Valid Acc.: 88.92%/88.88% \n",
            "6/100 | Cost: 50689.41 | Train/Valid Acc.: 89.52%/89.43% \n",
            "7/100 | Cost: 49100.82 | Train/Valid Acc.: 89.85%/89.93% \n",
            "8/100 | Cost: 47374.05 | Train/Valid Acc.: 90.20%/90.28% \n",
            "9/100 | Cost: 45877.52 | Train/Valid Acc.: 90.51%/90.56% \n",
            "10/100 | Cost: 44553.68 | Train/Valid Acc.: 90.79%/90.83% \n",
            "11/100 | Cost: 43690.34 | Train/Valid Acc.: 90.97%/90.93% \n",
            "12/100 | Cost: 42585.23 | Train/Valid Acc.: 91.20%/91.16% \n",
            "13/100 | Cost: 41238.33 | Train/Valid Acc.: 91.47%/91.51% \n",
            "14/100 | Cost: 40490.11 | Train/Valid Acc.: 91.63%/91.56% \n",
            "15/100 | Cost: 39396.49 | Train/Valid Acc.: 91.85%/91.89% \n",
            "16/100 | Cost: 38590.69 | Train/Valid Acc.: 92.02%/91.93% \n",
            "17/100 | Cost: 37980.61 | Train/Valid Acc.: 92.15%/91.96% \n",
            "18/100 | Cost: 37117.24 | Train/Valid Acc.: 92.33%/92.24% \n",
            "19/100 | Cost: 36426.56 | Train/Valid Acc.: 92.47%/92.36% \n",
            "20/100 | Cost: 35586.21 | Train/Valid Acc.: 92.64%/92.52% \n",
            "21/100 | Cost: 34837.96 | Train/Valid Acc.: 92.80%/92.63% \n",
            "22/100 | Cost: 34343.00 | Train/Valid Acc.: 92.90%/92.73% \n",
            "23/100 | Cost: 33767.44 | Train/Valid Acc.: 93.02%/92.94% \n",
            "24/100 | Cost: 33088.27 | Train/Valid Acc.: 93.16%/92.88% \n",
            "25/100 | Cost: 32685.40 | Train/Valid Acc.: 93.24%/93.13% \n",
            "26/100 | Cost: 32167.41 | Train/Valid Acc.: 93.35%/93.21% \n",
            "27/100 | Cost: 31799.08 | Train/Valid Acc.: 93.43%/93.28% \n",
            "28/100 | Cost: 31062.33 | Train/Valid Acc.: 93.58%/93.40% \n",
            "29/100 | Cost: 30590.38 | Train/Valid Acc.: 93.68%/93.51% \n",
            "30/100 | Cost: 29980.28 | Train/Valid Acc.: 93.80%/93.56% \n",
            "31/100 | Cost: 29600.43 | Train/Valid Acc.: 93.88%/93.64% \n",
            "32/100 | Cost: 29047.89 | Train/Valid Acc.: 94.00%/93.64% \n",
            "33/100 | Cost: 28852.25 | Train/Valid Acc.: 94.04%/93.73% \n",
            "34/100 | Cost: 28288.19 | Train/Valid Acc.: 94.15%/93.83% \n",
            "35/100 | Cost: 27758.67 | Train/Valid Acc.: 94.26%/93.88% \n",
            "36/100 | Cost: 27459.41 | Train/Valid Acc.: 94.32%/93.94% \n",
            "37/100 | Cost: 27114.09 | Train/Valid Acc.: 94.40%/94.02% \n",
            "38/100 | Cost: 26860.88 | Train/Valid Acc.: 94.45%/94.07% \n",
            "39/100 | Cost: 26619.18 | Train/Valid Acc.: 94.50%/94.09% \n",
            "40/100 | Cost: 26365.97 | Train/Valid Acc.: 94.55%/94.17% \n",
            "41/100 | Cost: 25928.55 | Train/Valid Acc.: 94.64%/94.23% \n",
            "42/100 | Cost: 25686.85 | Train/Valid Acc.: 94.69%/94.21% \n",
            "43/100 | Cost: 25479.68 | Train/Valid Acc.: 94.73%/94.36% \n",
            "44/100 | Cost: 25099.82 | Train/Valid Acc.: 94.81%/94.43% \n",
            "45/100 | Cost: 24869.63 | Train/Valid Acc.: 94.86%/94.41% \n",
            "46/100 | Cost: 24616.41 | Train/Valid Acc.: 94.91%/94.42% \n",
            "47/100 | Cost: 24328.66 | Train/Valid Acc.: 94.97%/94.55% \n",
            "48/100 | Cost: 24063.92 | Train/Valid Acc.: 95.03%/94.58% \n",
            "49/100 | Cost: 23937.34 | Train/Valid Acc.: 95.05%/94.58% \n",
            "50/100 | Cost: 23476.89 | Train/Valid Acc.: 95.15%/94.69% \n",
            "51/100 | Cost: 23269.72 | Train/Valid Acc.: 95.19%/94.72% \n",
            "52/100 | Cost: 23189.19 | Train/Valid Acc.: 95.21%/94.72% \n",
            "53/100 | Cost: 22774.79 | Train/Valid Acc.: 95.29%/94.77% \n",
            "54/100 | Cost: 22671.23 | Train/Valid Acc.: 95.31%/94.82% \n",
            "55/100 | Cost: 22337.42 | Train/Valid Acc.: 95.38%/94.89% \n",
            "56/100 | Cost: 21911.50 | Train/Valid Acc.: 95.47%/94.87% \n",
            "57/100 | Cost: 21923.07 | Train/Valid Acc.: 95.47%/94.88% \n",
            "58/100 | Cost: 21704.39 | Train/Valid Acc.: 95.51%/94.98% \n",
            "59/100 | Cost: 21278.47 | Train/Valid Acc.: 95.60%/95.02% \n",
            "60/100 | Cost: 21048.27 | Train/Valid Acc.: 95.65%/95.08% \n",
            "61/100 | Cost: 20645.37 | Train/Valid Acc.: 95.73%/95.07% \n",
            "62/100 | Cost: 20553.32 | Train/Valid Acc.: 95.75%/95.14% \n",
            "63/100 | Cost: 20714.56 | Train/Valid Acc.: 95.72%/95.18% \n",
            "64/100 | Cost: 20438.31 | Train/Valid Acc.: 95.78%/95.27% \n",
            "65/100 | Cost: 19943.30 | Train/Valid Acc.: 95.88%/95.27% \n",
            "66/100 | Cost: 20035.46 | Train/Valid Acc.: 95.86%/95.28% \n",
            "67/100 | Cost: 19816.77 | Train/Valid Acc.: 95.90%/95.31% \n",
            "68/100 | Cost: 19609.59 | Train/Valid Acc.: 95.95%/95.36% \n",
            "69/100 | Cost: 19506.03 | Train/Valid Acc.: 95.97%/95.43% \n",
            "70/100 | Cost: 19310.36 | Train/Valid Acc.: 96.01%/95.43% \n",
            "71/100 | Cost: 19137.72 | Train/Valid Acc.: 96.05%/95.44% \n",
            "72/100 | Cost: 18803.90 | Train/Valid Acc.: 96.11%/95.49% \n",
            "73/100 | Cost: 18677.31 | Train/Valid Acc.: 96.14%/95.55% \n",
            "74/100 | Cost: 18596.77 | Train/Valid Acc.: 96.16%/95.57% \n",
            "75/100 | Cost: 18516.23 | Train/Valid Acc.: 96.17%/95.65% \n",
            "76/100 | Cost: 18332.07 | Train/Valid Acc.: 96.21%/95.63% \n",
            "77/100 | Cost: 18263.04 | Train/Valid Acc.: 96.23%/95.67% \n",
            "78/100 | Cost: 17963.76 | Train/Valid Acc.: 96.29%/95.68% \n",
            "79/100 | Cost: 17894.73 | Train/Valid Acc.: 96.30%/95.68% \n",
            "80/100 | Cost: 17871.75 | Train/Valid Acc.: 96.31%/95.77% \n",
            "81/100 | Cost: 17595.49 | Train/Valid Acc.: 96.36%/95.76% \n",
            "82/100 | Cost: 17514.95 | Train/Valid Acc.: 96.38%/95.71% \n",
            "83/100 | Cost: 17330.79 | Train/Valid Acc.: 96.42%/95.84% \n",
            "84/100 | Cost: 17077.55 | Train/Valid Acc.: 96.47%/95.82% \n",
            "85/100 | Cost: 16732.21 | Train/Valid Acc.: 96.54%/95.84% \n",
            "86/100 | Cost: 16916.46 | Train/Valid Acc.: 96.50%/95.84% \n",
            "87/100 | Cost: 16720.79 | Train/Valid Acc.: 96.55%/95.87% \n",
            "88/100 | Cost: 16697.81 | Train/Valid Acc.: 96.55%/95.87% \n",
            "89/100 | Cost: 16513.64 | Train/Valid Acc.: 96.59%/95.91% \n",
            "90/100 | Cost: 16571.25 | Train/Valid Acc.: 96.58%/95.95% \n",
            "91/100 | Cost: 16318.01 | Train/Valid Acc.: 96.63%/95.94% \n",
            "92/100 | Cost: 15972.67 | Train/Valid Acc.: 96.70%/95.93% \n",
            "93/100 | Cost: 15938.17 | Train/Valid Acc.: 96.71%/95.98% \n",
            "94/100 | Cost: 15846.11 | Train/Valid Acc.: 96.73%/95.98% \n",
            "95/100 | Cost: 15754.05 | Train/Valid Acc.: 96.75%/95.98% \n",
            "96/100 | Cost: 15650.48 | Train/Valid Acc.: 96.77%/96.06% \n",
            "97/100 | Cost: 15466.32 | Train/Valid Acc.: 96.80%/96.08% \n",
            "98/100 | Cost: 15431.82 | Train/Valid Acc.: 96.81%/96.06% \n",
            "99/100 | Cost: 15397.32 | Train/Valid Acc.: 96.82%/96.06% \n",
            "100/100 | Cost: 15178.62 | Train/Valid Acc.: 96.86%/96.07% \n"
          ]
        }
      ],
      "source": [
        "history = nn.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGuc6mti3lIp"
      },
      "source": [
        "After the training is done, you should be able to plot the training and validation accuracy scores over time using the `history` dictionary returned by the fit function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "n79B9p-OzPIA"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(history['train_acc'],label='Training')\n",
        "plt.plot(history['valid_acc'],label='Validation')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPA_LeMzqyFc"
      },
      "source": [
        "## 4. Integrate our classifier into the scikit-learn pipeline and the randomized search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SP7V3OjInmQM"
      },
      "source": [
        "This time, we will use the same strategy as the second lab, trying to integrate everything from the raw dataset to the performance metrics into scikit-learn pipeline. \n",
        "\n",
        "- Task 1: Create a `Normalizer` class that extends BaseEstimator and TransformerMixin.\n",
        " - Your normalizer should do the following job:\n",
        "   - Normalizer: To make the features have the range [0, 1] and also **center the points to zero by subtracting 0.5 from the values.**\n",
        "   - Use NumPy's broadcasting to calculate (X / 255) - 0.5.\n",
        "\n",
        "\n",
        "- Task 2: Create a pipeline that integrates both normalizer and your neural network classifier.\n",
        "  - Your pipeline should contain the following modules.\n",
        "    - 'normalizer': Normalizer class\n",
        "    - 'classifier': `FullyConnectedNetwork` with default parameters but with epochs=10.\n",
        "\n",
        "- Task 3: Fit your pipeline on the datasets (`X_train`, `y_train`).\n",
        "  - You should **not** use `X_normalized` this time as the normalizer is now part of your pipeline. This means you might need to split your dataset again with `train_test_split` by using `X` and `y_integer`. Turn on stratification, and set `train_size` = 60000, `test_size` = 10000.\n",
        "  - Fit your pipeline and report the test score on `X_test` and `y_test` to `pipeline_score`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y_integer, test_size=0.142857,stratify=y) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "7KQyD1cf1Na8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\deept\\AppData\\Local\\Temp/ipykernel_8476/973144741.py:337: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  train_acc = ((np.sum(y_train == y_train_pred)).astype(np.float) / X_train.shape[0])       # CHANGE IT\n",
            "C:\\Users\\deept\\AppData\\Local\\Temp/ipykernel_8476/973144741.py:338: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  valid_acc = ((np.sum(y_valid == y_valid_pred)).astype(np.float) / X_valid.shape[0])       # CHANGE IT\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/10 | Cost: 107104.42 | Train/Valid Acc.: 77.85%/77.59% \n",
            "2/10 | Cost: 70447.23 | Train/Valid Acc.: 85.43%/85.01% \n",
            "3/10 | Cost: 56194.22 | Train/Valid Acc.: 88.38%/87.88% \n",
            "4/10 | Cost: 49723.95 | Train/Valid Acc.: 89.72%/89.24% \n",
            "5/10 | Cost: 47052.95 | Train/Valid Acc.: 90.27%/89.69% \n",
            "6/10 | Cost: 44784.90 | Train/Valid Acc.: 90.74%/90.09% \n",
            "7/10 | Cost: 43023.42 | Train/Valid Acc.: 91.10%/90.49% \n",
            "8/10 | Cost: 41400.10 | Train/Valid Acc.: 91.44%/90.73% \n",
            "9/10 | Cost: 39903.41 | Train/Valid Acc.: 91.75%/91.03% \n",
            "10/10 | Cost: 38452.78 | Train/Valid Acc.: 92.05%/91.36% \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Pipeline(steps=[('normalizer', Normalizer()),\n",
              "                ('classifier', FullyConnectedNetwork(epochs=10, l1=0, l2=0))])"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create: class Normalizer(BaseEstimator, TransformerMixin)\n",
        "#\n",
        "#\n",
        "class Normalizer(BaseEstimator, TransformerMixin):\n",
        "  \"\"\"\n",
        "  Normalizer: To make the features have the range [0, 1] and also center the points to zero by subtracting 0.5 from the values.\n",
        "   - Use NumPy's broadcasting to calculate (X / 255) - 0.5.\n",
        "  \"\"\"\n",
        "  def __init__(self):\n",
        "    return None\n",
        "  \n",
        "  def fit(self, X, y = None):\n",
        "    return self\n",
        "\n",
        "  def transform(self, X, y = None):\n",
        "    X = np.array((X / 255) - 0.5)\n",
        "    return X\n",
        "\n",
        "\n",
        "# Creating a pipeline\n",
        "# - scaler = Normalizer()\n",
        "# - classifier = FullyConnectedNetwork\n",
        "\n",
        "pipe = Pipeline([\n",
        "  ('normalizer', Normalizer()),\n",
        "  ('classifier', FullyConnectedNetwork(n_hidden=30, l2=0, l1=0, epochs=10, eta=0.001, validation_rate=0.3, shuffle=True, batch_size=1, init_technique=\"normal\", seed=None, debug=True))\n",
        "])\n",
        "\n",
        "pipe.fit(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "tQRQASa5bz89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9166\n"
          ]
        }
      ],
      "source": [
        "# REPORT YOUR SCORE HERE\n",
        "training_score = str(pipe.score(X_train, y_train))\n",
        "pipeline_score = str(pipe.score(X_test, y_test))        # CHANGE IT\n",
        "print(pipeline_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMdqSR8k4hRI"
      },
      "source": [
        "- Task 4: Randomized search\n",
        "  - After constructing your pipeline, we will perform a randomized search on it.\n",
        "  - Define your parameter grid with the following information:\n",
        "    - l1 of classifier: [0.001, 0.01, 0.1]\n",
        "    - l2 of classifier: [0.001, 0.01, 0.1]\n",
        "    - size of hidden layer of classifier: [30, 50, 100]\n",
        "    - learning rate of classifier: [0.0001, 0.0005, 0.001]\n",
        "    - initialization techniques of classifier: [normal, xavier, he]\n",
        "  - Run your randomized search with cv=3. Fit it on your previous `X_train` and `y_train`. \n",
        "    - Make 10 different attempts.\n",
        "    - Set `random_state` = 12345\n",
        "  - Report your best classifier and best score into the variables `best_classifier` and `best_score`.\n",
        "\n",
        "  - **Note that this task will take a few hours based on computing power, so you may not need to finish the run. We will only check if the logic is correct if you cannot finish the task before the submission.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['memory', 'steps', 'verbose', 'normalizer', 'classifier', 'classifier__batch_size', 'classifier__debug', 'classifier__epochs', 'classifier__eta', 'classifier__init_technique', 'classifier__l1', 'classifier__l2', 'classifier__n_hidden', 'classifier__seed', 'classifier__shuffle', 'classifier__validation_rate'])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pipe.get_params().keys() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "rysn4lmhmpBb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\deept\\AppData\\Local\\Temp/ipykernel_8476/973144741.py:337: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  train_acc = ((np.sum(y_train == y_train_pred)).astype(np.float) / X_train.shape[0])       # CHANGE IT\n",
            "C:\\Users\\deept\\AppData\\Local\\Temp/ipykernel_8476/973144741.py:338: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  valid_acc = ((np.sum(y_valid == y_valid_pred)).astype(np.float) / X_valid.shape[0])       # CHANGE IT\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/10 | Cost: 212238.27 | Train/Valid Acc.: 34.17%/34.32% \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\deept\\AppData\\Local\\Temp/ipykernel_8476/973144741.py:337: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  train_acc = ((np.sum(y_train == y_train_pred)).astype(np.float) / X_train.shape[0])       # CHANGE IT\n",
            "C:\\Users\\deept\\AppData\\Local\\Temp/ipykernel_8476/973144741.py:338: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  valid_acc = ((np.sum(y_valid == y_valid_pred)).astype(np.float) / X_valid.shape[0])       # CHANGE IT\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/10 | Cost: 83961.70 | Train/Valid Acc.: 73.96%/73.17% \n",
            "2/10 | Cost: 65246.50 | Train/Valid Acc.: 79.76%/79.12% \n",
            "3/10 | Cost: 52889.87 | Train/Valid Acc.: 83.60%/83.23% \n",
            "4/10 | Cost: 50816.05 | Train/Valid Acc.: 84.24%/83.79% \n",
            "5/10 | Cost: 46233.26 | Train/Valid Acc.: 85.66%/85.54% \n",
            "6/10 | Cost: 47453.40 | Train/Valid Acc.: 85.28%/84.85% \n",
            "7/10 | Cost: 46405.67 | Train/Valid Acc.: 85.61%/85.22% \n",
            "8/10 | Cost: 50815.14 | Train/Valid Acc.: 84.24%/83.99% \n",
            "9/10 | Cost: 45645.84 | Train/Valid Acc.: 85.84%/85.51% \n",
            "10/10 | Cost: 44713.32 | Train/Valid Acc.: 86.13%/85.98% \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\deept\\AppData\\Local\\Temp/ipykernel_8476/973144741.py:337: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  train_acc = ((np.sum(y_train == y_train_pred)).astype(np.float) / X_train.shape[0])       # CHANGE IT\n",
            "C:\\Users\\deept\\AppData\\Local\\Temp/ipykernel_8476/973144741.py:338: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  valid_acc = ((np.sum(y_valid == y_valid_pred)).astype(np.float) / X_valid.shape[0])       # CHANGE IT\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/10 | Cost: 87668.76 | Train/Valid Acc.: 72.81%/71.83% \n",
            "2/10 | Cost: 64509.58 | Train/Valid Acc.: 79.99%/79.11% \n",
            "3/10 | Cost: 59302.53 | Train/Valid Acc.: 81.61%/80.82% \n",
            "4/10 | Cost: 52496.92 | Train/Valid Acc.: 83.72%/82.93% \n",
            "5/10 | Cost: 47971.69 | Train/Valid Acc.: 85.12%/84.38% \n",
            "6/10 | Cost: 49675.38 | Train/Valid Acc.: 84.59%/83.85% \n",
            "7/10 | Cost: 48719.73 | Train/Valid Acc.: 84.89%/84.38% \n",
            "8/10 | Cost: 45968.15 | Train/Valid Acc.: 85.74%/84.95% \n",
            "9/10 | Cost: 44080.06 | Train/Valid Acc.: 86.33%/85.59% \n",
            "10/10 | Cost: 46808.63 | Train/Valid Acc.: 85.48%/84.63% \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\deept\\AppData\\Local\\Temp/ipykernel_8476/973144741.py:337: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  train_acc = ((np.sum(y_train == y_train_pred)).astype(np.float) / X_train.shape[0])       # CHANGE IT\n",
            "C:\\Users\\deept\\AppData\\Local\\Temp/ipykernel_8476/973144741.py:338: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  valid_acc = ((np.sum(y_valid == y_valid_pred)).astype(np.float) / X_valid.shape[0])       # CHANGE IT\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/10 | Cost: 79010.88 | Train/Valid Acc.: 75.50%/75.28% \n",
            "2/10 | Cost: 68734.75 | Train/Valid Acc.: 78.68%/78.13% \n",
            "3/10 | Cost: 56562.37 | Train/Valid Acc.: 82.46%/81.72% \n",
            "4/10 | Cost: 50459.04 | Train/Valid Acc.: 84.35%/83.83% \n",
            "5/10 | Cost: 47154.20 | Train/Valid Acc.: 85.38%/84.67% \n",
            "6/10 | Cost: 50492.71 | Train/Valid Acc.: 84.34%/83.90% \n",
            "7/10 | Cost: 45519.09 | Train/Valid Acc.: 85.88%/85.01% \n",
            "8/10 | Cost: 46624.32 | Train/Valid Acc.: 85.54%/84.81% \n",
            "9/10 | Cost: 47648.99 | Train/Valid Acc.: 85.22%/84.46% \n",
            "10/10 | Cost: 44828.35 | Train/Valid Acc.: 86.10%/85.52% \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\deept\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
            "27 fits failed out of a total of 30.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "5 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\deept\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\deept\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"C:\\Users\\deept\\AppData\\Local\\Temp/ipykernel_8476/973144741.py\", line 414, in fit\n",
            "    self.evaluate(i, X_train, X_valid, y_train, y_valid)\n",
            "  File \"C:\\Users\\deept\\AppData\\Local\\Temp/ipykernel_8476/973144741.py\", line 331, in evaluate\n",
            "    cost = self.cost(y_train,y_train_pred)      # CHANGE IT\n",
            "  File \"C:\\Users\\deept\\AppData\\Local\\Temp/ipykernel_8476/973144741.py\", line 200, in cost\n",
            "    y_pred_enc = one_hot(y_pred)\n",
            "  File \"C:\\Users\\deept\\AppData\\Local\\Temp/ipykernel_8476/970944179.py\", line 17, in one_hot\n",
            "    out[np.arange(m), y] = 1\n",
            "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\deept\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\deept\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"C:\\Users\\deept\\AppData\\Local\\Temp/ipykernel_8476/973144741.py\", line 414, in fit\n",
            "    self.evaluate(i, X_train, X_valid, y_train, y_valid)\n",
            "  File \"C:\\Users\\deept\\AppData\\Local\\Temp/ipykernel_8476/973144741.py\", line 331, in evaluate\n",
            "    cost = self.cost(y_train,y_train_pred)      # CHANGE IT\n",
            "  File \"C:\\Users\\deept\\AppData\\Local\\Temp/ipykernel_8476/973144741.py\", line 200, in cost\n",
            "    y_pred_enc = one_hot(y_pred)\n",
            "  File \"C:\\Users\\deept\\AppData\\Local\\Temp/ipykernel_8476/970944179.py\", line 17, in one_hot\n",
            "    out[np.arange(m), y] = 1\n",
            "IndexError: index 7 is out of bounds for axis 1 with size 1\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\deept\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\deept\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"C:\\Users\\deept\\AppData\\Local\\Temp/ipykernel_8476/973144741.py\", line 414, in fit\n",
            "    self.evaluate(i, X_train, X_valid, y_train, y_valid)\n",
            "  File \"C:\\Users\\deept\\AppData\\Local\\Temp/ipykernel_8476/973144741.py\", line 331, in evaluate\n",
            "    cost = self.cost(y_train,y_train_pred)      # CHANGE IT\n",
            "  File \"C:\\Users\\deept\\AppData\\Local\\Temp/ipykernel_8476/973144741.py\", line 200, in cost\n",
            "    y_pred_enc = one_hot(y_pred)\n",
            "  File \"C:\\Users\\deept\\AppData\\Local\\Temp/ipykernel_8476/970944179.py\", line 17, in one_hot\n",
            "    out[np.arange(m), y] = 1\n",
            "IndexError: index 7 is out of bounds for axis 1 with size 3\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\deept\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\deept\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"C:\\Users\\deept\\AppData\\Local\\Temp/ipykernel_8476/973144741.py\", line 414, in fit\n",
            "    self.evaluate(i, X_train, X_valid, y_train, y_valid)\n",
            "  File \"C:\\Users\\deept\\AppData\\Local\\Temp/ipykernel_8476/973144741.py\", line 331, in evaluate\n",
            "    cost = self.cost(y_train,y_train_pred)      # CHANGE IT\n",
            "  File \"C:\\Users\\deept\\AppData\\Local\\Temp/ipykernel_8476/973144741.py\", line 200, in cost\n",
            "    y_pred_enc = one_hot(y_pred)\n",
            "  File \"C:\\Users\\deept\\AppData\\Local\\Temp/ipykernel_8476/970944179.py\", line 17, in one_hot\n",
            "    out[np.arange(m), y] = 1\n",
            "IndexError: index 9 is out of bounds for axis 1 with size 6\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\deept\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\deept\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"C:\\Users\\deept\\AppData\\Local\\Temp/ipykernel_8476/973144741.py\", line 414, in fit\n",
            "    self.evaluate(i, X_train, X_valid, y_train, y_valid)\n",
            "  File \"C:\\Users\\deept\\AppData\\Local\\Temp/ipykernel_8476/973144741.py\", line 331, in evaluate\n",
            "    cost = self.cost(y_train,y_train_pred)      # CHANGE IT\n",
            "  File \"C:\\Users\\deept\\AppData\\Local\\Temp/ipykernel_8476/973144741.py\", line 200, in cost\n",
            "    y_pred_enc = one_hot(y_pred)\n",
            "  File \"C:\\Users\\deept\\AppData\\Local\\Temp/ipykernel_8476/970944179.py\", line 17, in one_hot\n",
            "    out[np.arange(m), y] = 1\n",
            "IndexError: index 4 is out of bounds for axis 1 with size 4\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\deept\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\deept\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"C:\\Users\\deept\\AppData\\Local\\Temp/ipykernel_8476/973144741.py\", line 414, in fit\n",
            "    self.evaluate(i, X_train, X_valid, y_train, y_valid)\n",
            "  File \"C:\\Users\\deept\\AppData\\Local\\Temp/ipykernel_8476/973144741.py\", line 331, in evaluate\n",
            "    cost = self.cost(y_train,y_train_pred)      # CHANGE IT\n",
            "  File \"C:\\Users\\deept\\AppData\\Local\\Temp/ipykernel_8476/973144741.py\", line 200, in cost\n",
            "    y_pred_enc = one_hot(y_pred)\n",
            "  File \"C:\\Users\\deept\\AppData\\Local\\Temp/ipykernel_8476/970944179.py\", line 17, in one_hot\n",
            "    out[np.arange(m), y] = 1\n",
            "IndexError: index 7 is out of bounds for axis 1 with size 7\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\deept\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\deept\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"C:\\Users\\deept\\AppData\\Local\\Temp/ipykernel_8476/973144741.py\", line 414, in fit\n",
            "    self.evaluate(i, X_train, X_valid, y_train, y_valid)\n",
            "  File \"C:\\Users\\deept\\AppData\\Local\\Temp/ipykernel_8476/973144741.py\", line 331, in evaluate\n",
            "    cost = self.cost(y_train,y_train_pred)      # CHANGE IT\n",
            "  File \"C:\\Users\\deept\\AppData\\Local\\Temp/ipykernel_8476/973144741.py\", line 200, in cost\n",
            "    y_pred_enc = one_hot(y_pred)\n",
            "  File \"C:\\Users\\deept\\AppData\\Local\\Temp/ipykernel_8476/970944179.py\", line 17, in one_hot\n",
            "    out[np.arange(m), y] = 1\n",
            "IndexError: index 8 is out of bounds for axis 1 with size 8\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "2 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\deept\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\deept\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"C:\\Users\\deept\\AppData\\Local\\Temp/ipykernel_8476/973144741.py\", line 414, in fit\n",
            "    self.evaluate(i, X_train, X_valid, y_train, y_valid)\n",
            "  File \"C:\\Users\\deept\\AppData\\Local\\Temp/ipykernel_8476/973144741.py\", line 331, in evaluate\n",
            "    cost = self.cost(y_train,y_train_pred)      # CHANGE IT\n",
            "  File \"C:\\Users\\deept\\AppData\\Local\\Temp/ipykernel_8476/973144741.py\", line 200, in cost\n",
            "    y_pred_enc = one_hot(y_pred)\n",
            "  File \"C:\\Users\\deept\\AppData\\Local\\Temp/ipykernel_8476/970944179.py\", line 17, in one_hot\n",
            "    out[np.arange(m), y] = 1\n",
            "IndexError: index 9 is out of bounds for axis 1 with size 8\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\deept\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\deept\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"C:\\Users\\deept\\AppData\\Local\\Temp/ipykernel_8476/973144741.py\", line 414, in fit\n",
            "    self.evaluate(i, X_train, X_valid, y_train, y_valid)\n",
            "  File \"C:\\Users\\deept\\AppData\\Local\\Temp/ipykernel_8476/973144741.py\", line 331, in evaluate\n",
            "    cost = self.cost(y_train,y_train_pred)      # CHANGE IT\n",
            "  File \"C:\\Users\\deept\\AppData\\Local\\Temp/ipykernel_8476/973144741.py\", line 200, in cost\n",
            "    y_pred_enc = one_hot(y_pred)\n",
            "  File \"C:\\Users\\deept\\AppData\\Local\\Temp/ipykernel_8476/970944179.py\", line 17, in one_hot\n",
            "    out[np.arange(m), y] = 1\n",
            "IndexError: index 7 is out of bounds for axis 1 with size 4\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "3 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\deept\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\deept\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"C:\\Users\\deept\\AppData\\Local\\Temp/ipykernel_8476/973144741.py\", line 414, in fit\n",
            "    self.evaluate(i, X_train, X_valid, y_train, y_valid)\n",
            "  File \"C:\\Users\\deept\\AppData\\Local\\Temp/ipykernel_8476/973144741.py\", line 331, in evaluate\n",
            "    cost = self.cost(y_train,y_train_pred)      # CHANGE IT\n",
            "  File \"C:\\Users\\deept\\AppData\\Local\\Temp/ipykernel_8476/973144741.py\", line 200, in cost\n",
            "    y_pred_enc = one_hot(y_pred)\n",
            "  File \"C:\\Users\\deept\\AppData\\Local\\Temp/ipykernel_8476/970944179.py\", line 17, in one_hot\n",
            "    out[np.arange(m), y] = 1\n",
            "IndexError: index 7 is out of bounds for axis 1 with size 5\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\deept\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\deept\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"C:\\Users\\deept\\AppData\\Local\\Temp/ipykernel_8476/973144741.py\", line 414, in fit\n",
            "    self.evaluate(i, X_train, X_valid, y_train, y_valid)\n",
            "  File \"C:\\Users\\deept\\AppData\\Local\\Temp/ipykernel_8476/973144741.py\", line 331, in evaluate\n",
            "    cost = self.cost(y_train,y_train_pred)      # CHANGE IT\n",
            "  File \"C:\\Users\\deept\\AppData\\Local\\Temp/ipykernel_8476/973144741.py\", line 200, in cost\n",
            "    y_pred_enc = one_hot(y_pred)\n",
            "  File \"C:\\Users\\deept\\AppData\\Local\\Temp/ipykernel_8476/970944179.py\", line 17, in one_hot\n",
            "    out[np.arange(m), y] = 1\n",
            "IndexError: index 7 is out of bounds for axis 1 with size 2\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\deept\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\deept\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"C:\\Users\\deept\\AppData\\Local\\Temp/ipykernel_8476/973144741.py\", line 414, in fit\n",
            "    self.evaluate(i, X_train, X_valid, y_train, y_valid)\n",
            "  File \"C:\\Users\\deept\\AppData\\Local\\Temp/ipykernel_8476/973144741.py\", line 331, in evaluate\n",
            "    cost = self.cost(y_train,y_train_pred)      # CHANGE IT\n",
            "  File \"C:\\Users\\deept\\AppData\\Local\\Temp/ipykernel_8476/973144741.py\", line 200, in cost\n",
            "    y_pred_enc = one_hot(y_pred)\n",
            "  File \"C:\\Users\\deept\\AppData\\Local\\Temp/ipykernel_8476/970944179.py\", line 17, in one_hot\n",
            "    out[np.arange(m), y] = 1\n",
            "IndexError: index 2 is out of bounds for axis 1 with size 2\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\deept\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\deept\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"C:\\Users\\deept\\AppData\\Local\\Temp/ipykernel_8476/973144741.py\", line 414, in fit\n",
            "    self.evaluate(i, X_train, X_valid, y_train, y_valid)\n",
            "  File \"C:\\Users\\deept\\AppData\\Local\\Temp/ipykernel_8476/973144741.py\", line 331, in evaluate\n",
            "    cost = self.cost(y_train,y_train_pred)      # CHANGE IT\n",
            "  File \"C:\\Users\\deept\\AppData\\Local\\Temp/ipykernel_8476/973144741.py\", line 200, in cost\n",
            "    y_pred_enc = one_hot(y_pred)\n",
            "  File \"C:\\Users\\deept\\AppData\\Local\\Temp/ipykernel_8476/970944179.py\", line 17, in one_hot\n",
            "    out[np.arange(m), y] = 1\n",
            "IndexError: index 3 is out of bounds for axis 1 with size 1\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\deept\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\deept\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"C:\\Users\\deept\\AppData\\Local\\Temp/ipykernel_8476/973144741.py\", line 414, in fit\n",
            "    self.evaluate(i, X_train, X_valid, y_train, y_valid)\n",
            "  File \"C:\\Users\\deept\\AppData\\Local\\Temp/ipykernel_8476/973144741.py\", line 331, in evaluate\n",
            "    cost = self.cost(y_train,y_train_pred)      # CHANGE IT\n",
            "  File \"C:\\Users\\deept\\AppData\\Local\\Temp/ipykernel_8476/973144741.py\", line 200, in cost\n",
            "    y_pred_enc = one_hot(y_pred)\n",
            "  File \"C:\\Users\\deept\\AppData\\Local\\Temp/ipykernel_8476/970944179.py\", line 17, in one_hot\n",
            "    out[np.arange(m), y] = 1\n",
            "IndexError: index 3 is out of bounds for axis 1 with size 2\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\deept\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\deept\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"C:\\Users\\deept\\AppData\\Local\\Temp/ipykernel_8476/973144741.py\", line 414, in fit\n",
            "    self.evaluate(i, X_train, X_valid, y_train, y_valid)\n",
            "  File \"C:\\Users\\deept\\AppData\\Local\\Temp/ipykernel_8476/973144741.py\", line 331, in evaluate\n",
            "    cost = self.cost(y_train,y_train_pred)      # CHANGE IT\n",
            "  File \"C:\\Users\\deept\\AppData\\Local\\Temp/ipykernel_8476/973144741.py\", line 200, in cost\n",
            "    y_pred_enc = one_hot(y_pred)\n",
            "  File \"C:\\Users\\deept\\AppData\\Local\\Temp/ipykernel_8476/970944179.py\", line 17, in one_hot\n",
            "    out[np.arange(m), y] = 1\n",
            "IndexError: index 8 is out of bounds for axis 1 with size 5\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "5 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\deept\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\deept\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"C:\\Users\\deept\\AppData\\Local\\Temp/ipykernel_8476/973144741.py\", line 414, in fit\n",
            "    self.evaluate(i, X_train, X_valid, y_train, y_valid)\n",
            "  File \"C:\\Users\\deept\\AppData\\Local\\Temp/ipykernel_8476/973144741.py\", line 331, in evaluate\n",
            "    cost = self.cost(y_train,y_train_pred)      # CHANGE IT\n",
            "  File \"C:\\Users\\deept\\AppData\\Local\\Temp/ipykernel_8476/973144741.py\", line 200, in cost\n",
            "    y_pred_enc = one_hot(y_pred)\n",
            "  File \"C:\\Users\\deept\\AppData\\Local\\Temp/ipykernel_8476/970944179.py\", line 17, in one_hot\n",
            "    out[np.arange(m), y] = 1\n",
            "IndexError: index 9 is out of bounds for axis 1 with size 9\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "C:\\Users\\deept\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [    nan     nan     nan     nan     nan     nan     nan     nan     nan\n",
            " 0.85635]\n",
            "  warnings.warn(\n",
            "C:\\Users\\deept\\AppData\\Local\\Temp/ipykernel_8476/973144741.py:337: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  train_acc = ((np.sum(y_train == y_train_pred)).astype(np.float) / X_train.shape[0])       # CHANGE IT\n",
            "C:\\Users\\deept\\AppData\\Local\\Temp/ipykernel_8476/973144741.py:338: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  valid_acc = ((np.sum(y_valid == y_valid_pred)).astype(np.float) / X_valid.shape[0])       # CHANGE IT\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/10 | Cost: 117195.30 | Train/Valid Acc.: 75.77%/75.37% \n",
            "2/10 | Cost: 85977.79 | Train/Valid Acc.: 82.22%/81.87% \n",
            "3/10 | Cost: 82982.57 | Train/Valid Acc.: 82.84%/82.43% \n",
            "4/10 | Cost: 74646.75 | Train/Valid Acc.: 84.56%/84.19% \n",
            "5/10 | Cost: 70145.12 | Train/Valid Acc.: 85.50%/85.23% \n",
            "6/10 | Cost: 69822.80 | Train/Valid Acc.: 85.56%/85.58% \n",
            "7/10 | Cost: 69465.94 | Train/Valid Acc.: 85.64%/85.58% \n",
            "8/10 | Cost: 68533.41 | Train/Valid Acc.: 85.83%/85.82% \n",
            "9/10 | Cost: 71826.11 | Train/Valid Acc.: 85.15%/84.98% \n",
            "10/10 | Cost: 67232.47 | Train/Valid Acc.: 86.10%/85.99% \n",
            "Pipeline(steps=[('normalizer', Normalizer()),\n",
            "                ('classifier',\n",
            "                 FullyConnectedNetwork(epochs=10, l1=0.01, l2=0.01,\n",
            "                                       n_hidden=50))]) 0.85635\n"
          ]
        }
      ],
      "source": [
        "\n",
        "l1_values = [0.001,0.01,0.1]\n",
        "l2_values = [0.001,0.01,0.1]\n",
        "n_hidden_values = [30,50,100]\n",
        "eta_rates = [0.0001,0.0005,0.001]\n",
        "init_technique_values = ['normal', 'xavier','he']\n",
        "\n",
        "parameters = {'classifier__l1': l1_values,\n",
        "               'classifier__l2': l2_values,\n",
        "               'classifier__n_hidden': n_hidden_values,\n",
        "               'classifier__eta': eta_rates,\n",
        "               'classifier__init_technique': init_technique_values}                           # CHANGE IT\n",
        "\n",
        "\n",
        "\n",
        "grid = RandomizedSearchCV(estimator = pipe, param_distributions = parameters, cv = 3, n_iter = 10, random_state=12345)          # CHANGE IT\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "best_classifier = grid.best_estimator_          # CHANGE IT\n",
        "best_score = grid.best_score_                   # CHANGE IT\n",
        "\n",
        "print(best_classifier, best_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9gSkzvszU1K"
      },
      "source": [
        "# END"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "HW2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
